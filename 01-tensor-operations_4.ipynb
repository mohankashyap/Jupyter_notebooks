{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding different Pytorch tensor functions\n",
    "\n",
    "### Pytorch library\n",
    "\n",
    "Pytorch is an open-source machine learning library that has been developed by Facebook's AI Research lab (FAIR). It is mostly used for developing algorithms related to machine learning and deep learning. Additionally, this library can perform operations related to concepts of linear algebra and some optimization problem methods.\n",
    "\n",
    "### Pytorch Tensor\n",
    "The fundamental unit of this library is the tensor data structure. \n",
    "The tensor data structure is a multidimensional array containing a particular datatype as it's input. It is the basic building block for all the functions described in PyTorch. \n",
    "In this notebook, we discuss five different PyTorch tensor functions that are used to modify tensors to get the required outputs. They are:\n",
    "* The norm of a tensor \n",
    "* Dot product of a tensor\n",
    "* The inverse of a tensor, \n",
    "* Selecting index from a tensor \n",
    "* Cosine similarity of two tensors: The function cosine similarity is generated using function 1 which is the tensor norm and function 2 which is a tensor dot product.\n",
    "\n",
    "#### Tensor.norm\n",
    "Norm function gives information about the distance of a particular vector from the origin. Additionally, it provides information about the distance between the two vectors in an N-dimensional space, often referred to as the euclidean norm.\n",
    "\n",
    "The formula for the vector norm with 3 elements is defined as:\n",
    "\n",
    "<img src=\"vector_norm_with_3_dim.png\">\n",
    "\n",
    "The formula for the matrix norm referred to as Frobenius norm is defined as:\n",
    "\n",
    "<img src=\"Forbenious_matrix_norm.png\">\n",
    "\n",
    "Norm functions are vastly used in the machine learning algorithm's development. Few of the examples are described below:\n",
    "\n",
    "* They are used as regularizer functions, mean square error functions in regression problems. \n",
    "* In the KNN algorithm norm function is used to measure the distance between two vectors.\n",
    "* Loss functions such as mean square errors and mean absolute error.\n",
    "\n",
    "#### Tensor.dotproduct\n",
    "Computes the dot product between two tensors. \n",
    "\n",
    "It gives the information related to the orientation of each of the vector and when superimposed over one another how the magnitude is increased or decreased in the resulting vector based on their initial orientation.\n",
    "\n",
    "The formula for dot product is:\n",
    "\n",
    "<img src=\"Dot_product_of_two_vectors.png\">\n",
    "\n",
    "\n",
    "It is extensively used in machine applications, a few of them are described below:\n",
    "* In NLP applications it is used to understand how two documents are similar by computing the dot product of their document word vectors\n",
    "* It forms the fundamental unit for computing the output of the neurons in machine learning and deep learning applications.\n",
    "\n",
    "####  Tensor.inverse\n",
    "\n",
    "Computes the inverse of the square matrix input. Input can be batches of 2D square tensors, in which case this function would return a tensor composed of individual inverses. \n",
    "Gauss Jordan matrix elimination method and Cramer's rule method are some of the methods by which the inverse of the matrices are found.\n",
    " \n",
    "Applications of the torch. inverse function in machine learning is described below:\n",
    "* It is used in the linear regression algorithm inverse can help us to compute resultant weight vector or referred to as regression coefficients in the matrix form. \n",
    "Let\n",
    "* X -> be the input data (training data)\n",
    "* X' -> Transpose of the input data\n",
    "* Y -> be the output data (variables we are trying to predict)\n",
    "* B -> Weight vector(the slope coefficients or coefficients of the linear model) \n",
    "\n",
    "* The weight vector is calulated as :\n",
    "\n",
    "<img src=\"Linear_regression_weight_vector_calculation.png\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Tensor.select_index\n",
    "\n",
    "Index select functions are possibly used for selecting a particular range of data to understand and get more insights about the data. This function can be used to generate required batch sizes while training the data in machine learning and deep learning applications.\n",
    "\n",
    "#### Tesnor.consine_similarity\n",
    "\n",
    "Cosine similarity measures the similarity between two vectors. It is measured by the cosine of the angle between two vectors and determines whether two vectors are pointing in roughly the same direction. In finding out the similarity, firstly we calculate the norm corresponding to the two inputs provided, and then further on calculating the dot product. Following formula gives the information about the cosine similarity:\n",
    "\n",
    "\n",
    "<img src=\"Cosine_similarity_formula.png\">\n",
    "\n",
    "\n",
    "cosine(angle) gives the similarity score between the two vectors. The higher the score more similar are the vectors.\n",
    "\n",
    "#### Applications of cosine similarity functions \n",
    "\n",
    "In natural language processing cosine similarity can be used to find the similarity between the two documents utilizing the word document vector. \n",
    "\n",
    "For the feature vector in machine learning and deep learning problems if we find that two feature vectors are very similar, but with a slight difference, then we can also use it to reduce the dimensionality of the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import torch and other required modules\n",
    "import torch\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 1 - Torch.norm\n",
    "This PyTorch function returns a vector norm or matrix norm based on the tensor input provided(i.e. vector or matrix).\n",
    "\n",
    "Vector norm - Norm of a vector is used to describe the magnitude of an N-dimensional vector. Norm intuitively gives information about the distance of the vector from the origin.\n",
    "\n",
    "Matrix norm -  Forbenious norm is used to calculate the norm of the matrix, but there are other kinds of norms such as maximum absolute column sum norm, spectral norm, and maximum absolute column row norm.\n",
    "\n",
    "The following examples give a method of calculating norm using torch tensors\n",
    "\n",
    "* Example 1: We calculate the norm of a vector using the euclidean norm method.\n",
    "* Example 2: We calculate the norm of a matrix using the Frobenius norm\n",
    "\n",
    "This function takes in the following arguments:\n",
    "\n",
    "        input (Tensor): the input tensor\n",
    "        p (int, float, inf, -inf, 'fro', 'nuc', optional): the order of norm. Default: fro\n",
    "        The following norms can be calculated:\n",
    "\n",
    "           =====  ============================  ==========================\n",
    "            ord    matrix norm                   vector norm\n",
    "            =====  ============================  ==========================\n",
    "            None   Frobenius norm                2-norm\n",
    "            'fro'  Frobenius norm                --\n",
    "            'nuc'  nuclear norm                  --\n",
    "            Other  as vec norm when dim is None  sum(abs(x)**ord)**(1./ord)\n",
    "            =====  ============================  ==========================\n",
    "\n",
    "        dim (int, 2-tuple of ints, 2-list of ints, optional): If it is an int,\n",
    "            vector norm will be calculated, if it is 2-tuple of ints, matrix norm\n",
    "            will be calculated. If the value is None, matrix norm will be calculated\n",
    "            when the input tensor only has two dimensions, vector norm will be\n",
    "            calculated when the input tensor only has one dimension. If the input\n",
    "            tensor has more than two dimensions, the vector norm will be applied to\n",
    "            last dimension.\n",
    "        keepdim (bool, optional): whether the output tensors have :attr:`dim`\n",
    "            retained or not. Ignored if :attr:`dim` = ``None`` and\n",
    "            :attr:`out` = ``None``. Default: ``False``\n",
    "        out (Tensor, optional): the output tensor. Ignored if\n",
    "            :attr:`dim` = ``None`` and :attr:`out` = ``None``.\n",
    "        dtype (:class:`torch.dtype`, optional): the desired data type of\n",
    "            returned tensor. If specified, the input tensor is casted to\n",
    "            :attr:'dtype' while performing the operation. Default: None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vector norm is:7.4161983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\70725454\\Anaconda3\\envs\\01-pytorch-basics\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Example 1 - norm of a vector\n",
    "import numpy as np\n",
    "\n",
    "def vector_norm_caluclator(input_numpy_array):\n",
    "    input_tensor_vector = np.array(input_numpy_array,dtype=np.float64)\n",
    "    torch_tesnor_vector = torch.from_numpy(input_tensor_vector)\n",
    "    torch_norm_output = torch.norm(torch.tensor(torch_tesnor_vector,dtype=torch.float),dim=0)\n",
    "    return torch_norm_output.numpy()\n",
    "\n",
    "input_numpy_array = [1,2,3,4,5]\n",
    "output = vector_norm_caluclator(input_numpy_array)\n",
    "print (\"The vector norm is:\"+str(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we give a 5 elements vector array as the input, which is provided through the NumPy library and it's converted to torch tensor array using PyTorch library. Norm is calculated is torch.norm function and finally, convert to NumPy array and return the norm output which will be 1 dimension output.\n",
    "\n",
    "For this example : \n",
    "* input = [1,2,3,4,5] \n",
    "* output = The vector norm is:7.416198487095663"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The matrix norm is:[2.236068 5.      ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\70725454\\Anaconda3\\envs\\01-pytorch-basics\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Example 2 - norm of a matrix\n",
    "import numpy as np\n",
    "\n",
    "def matrix_norm_caluclator(input_numpy_array):\n",
    "    input_tensor_vector = np.matrix(input_numpy_array,dtype=np.float64)\n",
    "    torch_tesnor_vector = torch.from_numpy(input_tensor_vector)\n",
    "    torch_norm_output = torch.norm(torch.tensor(torch_tesnor_vector,dtype=torch.float),p='fro',dim=1)\n",
    "    return torch_norm_output.numpy()\n",
    "\n",
    "input_numpy_array = [[1.,2.],[3.,4.]]\n",
    "\n",
    "output = matrix_norm_caluclator(input_numpy_array)\n",
    "print (\"The matrix norm is:\"+str(output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix norm in our case is called the Frobenius norm. In this example, we give a (2,2) dimensional matrix as input through a NumPy matrix and it's converted to torch tensor array. The torch.norm function is used to calculate the norm of the matrix and is converted to a NumPy array. \n",
    "\n",
    "For this example : input = [[1,2],[3,4]] \n",
    "\n",
    "\n",
    "*  `matrix    col0   col1`\n",
    "\n",
    "* ` row0       1      2`\n",
    "\n",
    "* ` row1       3      4`\n",
    "\n",
    "\n",
    "a) Since the dim=0 the output of the norm will be a row vector as the norm will be calculated across each column:\n",
    "\n",
    "* col0 : $squareroot(1^2+3^2)$ = 3.16\n",
    "\n",
    "* col1 : $squareroot(2^2+4^2)$ = 4.47\n",
    "\n",
    "* The matrix norm is : [3.16, 4.47]\n",
    "\n",
    "b) Since the dim=1 the output of the norm will be a row vector as the norm will be calculated across each column:\n",
    "\n",
    "* row0 : $squareroot(1^2+2^2)$ = 2.23\n",
    "\n",
    "* row1 : $squareroot(3^2+4^2)$ = 5\n",
    "\n",
    "* The matrix norm is : [3.16, 4.47]\n",
    "\n",
    "c) with default dim=None, the Frobenius norm is calculated which Square root of the sum of all elements:\n",
    "\n",
    "* The norm output is : $sqrt(1^2+2^2+3^2+4^2)$ = 7.416198487095663\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\70725454\\Anaconda3\\envs\\01-pytorch-basics\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-ac55137f53e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0minput_numpy_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvector_norm_caluclator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_numpy_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"The vector norm is:\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-ac55137f53e4>\u001b[0m in \u001b[0;36mvector_norm_caluclator\u001b[1;34m(input_numpy_array)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor_vector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtorch_tesnor_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor_vector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtorch_norm_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch_tesnor_vector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'fro'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch_norm_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\01-pytorch-basics\\lib\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36mnorm\u001b[1;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[0m_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# noqa: C416 TODO: rewrite as list(range(m))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrobenius_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrobenius_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking (to illustrate when it breaks)\n",
    "def vector_norm_caluclator(input_numpy_array):\n",
    "    input_tensor_vector = np.array(input_numpy_array,dtype=np.float64)\n",
    "    print (np.shape(input_tensor_vector))\n",
    "    torch_tesnor_vector = torch.from_numpy(input_tensor_vector)\n",
    "    torch_norm_output = torch.norm(torch.tensor(torch_tesnor_vector),p='fro',dim=1)\n",
    "    return torch_norm_output.numpy()\n",
    "\n",
    "input_numpy_array = [1,2,3,4,5]\n",
    "output = vector_norm_caluclator(input_numpy_array)\n",
    "print (\"The vector norm is:\"+str(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we provide the same input to the system but we change the default dimension parameter which is `dim` while calculating the norm. Since we pass the input as a 1d array with the 5 elements, the output for `dim=0` parameter will be calculated by computing the norm across all the 1d array elements. If the `dim=1` since no elements are corresponding to the other dimension the output throws an error, that the dimension out of range.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applications of norm function : \n",
    "This function is used to calculate the norm of the vector, it's typically useful while calculating the distance of the vector from origin or from another vector. In machine learning, L1 and L2 norms are typically used as regularizers in regression problems. They are used to calculate the distance between two vectors like in mean square error calculation( the difference between the actual vector and output vector) which is also a performance measure in linear regression. Norm is applied to various different concepts in machine learning and its a quite essential function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Function 2 - Torch.dot\n",
    "This PyTorch function Computes the dot product (inner product) of two tensors.\n",
    "\n",
    "torch.dot function is evaluated as follows:\n",
    "\n",
    "* Example1: \n",
    "* a = [1.,2.] b = [3.,4.]\n",
    "  dot_prod = $1*3+2*4$ = 11.0\n",
    "* Example 2:\n",
    "* a = [1.,2.,5.] b = [3.,4.,10.]\n",
    "  dot_prod = $1*3+2*4+5*10$ = 61.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dot product is:11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\70725454\\Anaconda3\\envs\\01-pytorch-basics\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# Example 1 - working\n",
    "import numpy as np\n",
    "\n",
    "def dot_product_calculator(input_numpy_array1, input_numpy_arry2):\n",
    "    input_tensor_vector1 = np.array(input_numpy_array1,dtype=np.float64)\n",
    "    input_tensor_vector2 = np.array(input_numpy_array2,dtype=np.float64)\n",
    "    torch_tesnor_vector1 = torch.from_numpy(input_tensor_vector1)\n",
    "    torch_tesnor_vector2 = torch.from_numpy(input_tensor_vector2)\n",
    "    torch_norm_output = torch.dot(torch.tensor(torch_tesnor_vector1),torch.tensor(torch_tesnor_vector2))\n",
    "    return torch_norm_output.numpy()\n",
    "\n",
    "input_numpy_array1 = [1.,2.]\n",
    "input_numpy_array2 = [3.,4.]\n",
    "output = dot_product_calculator(input_numpy_array1,input_numpy_array2)\n",
    "print (\"The dot product is:\"+str(output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dot product is computed with the input arrays as \n",
    "input_1 = [1,2]\n",
    "input_2 = [3,4]\n",
    "\n",
    "output is = 1 * 3 + 2 * 4 = 11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dot product is:61.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\70725454\\Anaconda3\\envs\\01-pytorch-basics\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# Example 2 - working\n",
    "import numpy as np\n",
    "\n",
    "def dot_product_calculator(input_numpy_array1, input_numpy_arry2):\n",
    "    input_tensor_vector1 = np.array(input_numpy_array1,dtype=np.float64)\n",
    "    input_tensor_vector2 = np.array(input_numpy_array2,dtype=np.float64)\n",
    "    torch_tesnor_vector1 = torch.from_numpy(input_tensor_vector1)\n",
    "    torch_tesnor_vector2 = torch.from_numpy(input_tensor_vector2)\n",
    "    torch_norm_output = torch.dot(torch.tensor(torch_tesnor_vector1),torch.tensor(torch_tesnor_vector2))\n",
    "    return torch_norm_output.numpy()\n",
    "\n",
    "input_numpy_array1 = [1.,2.,5.]\n",
    "input_numpy_array2 = [3.,4.,10.]\n",
    "output = dot_product_calculator(input_numpy_array1,input_numpy_array2)\n",
    "print (\"The dot product is:\"+str(output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dot product is computed with the input arrays as \n",
    "input_1 = [1,2,5]\n",
    "input_2 = [3,4,10]\n",
    "\n",
    "output is = 1 * 3 + 2 * 4 + 10 * 5 = 61\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\70725454\\Anaconda3\\envs\\01-pytorch-basics\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "dot() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-176-a899ad778646>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0minput_numpy_array3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdot_product_calculator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_numpy_array1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_numpy_array2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_numpy_array3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"The dot product is:\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-176-a899ad778646>\u001b[0m in \u001b[0;36mdot_product_calculator\u001b[1;34m(input_numpy_array1, input_numpy_arry2, input_numpy_array3)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtorch_tesnor_vector3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor_vector3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mtorch_norm_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch_tesnor_vector1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch_tesnor_vector2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch_tesnor_vector3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch_norm_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: dot() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking (to illustrate when it breaks)\n",
    "import numpy as np\n",
    "\n",
    "def dot_product_calculator(input_numpy_array1, input_numpy_arry2,input_numpy_array3):\n",
    "    input_tensor_vector1 = np.array(input_numpy_array1,dtype=np.float64)\n",
    "    input_tensor_vector2 = np.array(input_numpy_array2,dtype=np.float64)\n",
    "    input_tensor_vector3 = np.array(input_numpy_array3,dtype=np.float64)\n",
    "    \n",
    "    torch_tesnor_vector1 = torch.from_numpy(input_tensor_vector1)\n",
    "    torch_tesnor_vector2 = torch.from_numpy(input_tensor_vector2)\n",
    "    torch_tesnor_vector3 = torch.from_numpy(input_tensor_vector3)\n",
    "    \n",
    "    torch_norm_output = torch.dot(torch.tensor(torch_tesnor_vector1),torch.tensor(torch_tesnor_vector2),torch.tensor(torch_tesnor_vector3))\n",
    "    return torch_norm_output.numpy()\n",
    "\n",
    "input_numpy_array1 = [1.,2.,5.]\n",
    "input_numpy_array2 = [3.,4.,10.]\n",
    "input_numpy_array3 = [3.,4.,20.]\n",
    "\n",
    "output = dot_product_calculator(input_numpy_array1,input_numpy_array2,input_numpy_array3)\n",
    "print (\"The dot product is:\"+str(output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor.dot functions compute the dot product of two tensors. Giving an additional tensor to compute the dot product will throw an error of additional position of arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The applications of dot product functions:\n",
    "\n",
    "- In NLP application while computing the similarity score (i.e. cosine similarity) between the two documents we use the dot product.\n",
    "- It forms a basic computation element of linear algebra. Deep learning algorithms always using dot product multiplication(i.e. for example: In calculating the output of a neuron)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 3 - Torch.inverse\n",
    "\n",
    "Computes the inverse of the square matrix input. Input can be in batches of 2D square tensors, in which case this function would return a tensor composed of individual inverses.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0000,  1.0000],\n",
       "        [ 1.5000, -0.5000]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 - working\n",
    "import numpy as np\n",
    "\n",
    "inverse_output = torch.empty(2,2)\n",
    "\n",
    "input_matrix = [[1.,2.],[3.,4.]]\n",
    "torch.inverse(torch.tensor(input_matrix), out = inverse_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function calculates the inverse of the square matrix which is of dimension (2,2).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.7934, -1.2781],\n",
      "         [ 1.1620,  0.0875]],\n",
      "\n",
      "        [[ 0.9045,  0.3208],\n",
      "         [ 0.1014, -0.5015]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\70725454\\Anaconda3\\envs\\01-pytorch-basics\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0533,  0.7784],\n",
       "         [-0.7077,  1.0922]],\n",
       "\n",
       "        [[ 1.0316,  0.6599],\n",
       "         [ 0.2085, -1.8606]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inverse_output = torch.empty(2,2,2)\n",
    "\n",
    "input_matrix = torch.randn(2,2,2)\n",
    "print (input_matrix)\n",
    "torch.inverse(torch.tensor(input_matrix), out = inverse_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we randomly create the input matrices from a normal distribution. The input size is a 3-dimensional tensor for which we are calculating the inverses. The input size is (2,2,2) which generates two (2,2) matrices and it gives the inverse of those two matrices as well in a single command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1338, -0.4692, -0.2628],\n",
      "         [-0.7250, -2.2944,  1.1749]],\n",
      "\n",
      "        [[ 1.0984,  0.4513, -0.3974],\n",
      "         [ 0.9117, -0.2703, -0.8021]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\70725454\\Anaconda3\\envs\\01-pytorch-basics\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "A must be batches of square matrices, but they are 3 by 2 matrices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-179-059260d1c5d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0minput_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minverse_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: A must be batches of square matrices, but they are 3 by 2 matrices"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking (to illustrate when it breaks)\n",
    "import numpy as np\n",
    "\n",
    "inverse_output = torch.empty(2,2,3)\n",
    "\n",
    "input_matrix = torch.randn(2,2,3)\n",
    "print (input_matrix)\n",
    "torch.inverse(torch.tensor(input_matrix), out = inverse_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we randomly create the input matrices which is from a normal distribution. The input size is a 3-dimensional tensor for which we are calculating the inverses. The input size is (2,2,3) which generates two (3,2) matrices for which we cannot obtain the inverse as these are rectangular matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applications of inverse functions in machine learning applications:\n",
    "\n",
    "One of the possible application of inverse of matrix is while solving linear regression in a form of matrix formulation.\n",
    "\n",
    "- X -> be the input data (training data)\n",
    "- X' -> Transpose of the input data\n",
    "- Y -> be the output data (variables we are trying to predict)\n",
    "- B -> Weight vector \n",
    "\n",
    "- The weight vector is calulated as :\n",
    "\n",
    "<img src=\"Linear_regression_weight_vector_calculation.png\">\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 4 - Torch.index_select\n",
    "\n",
    "Returns a new tensor which indexes the input tensor along dimension dim using the entries in the index which is a LongTensor.\n",
    "\n",
    "The returned tensor has the same number of dimensions as the original tensor (input). The dimension has the same size as the length of the index; other dimensions have the same size as in the original tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0437,  1.8346],\n",
      "        [-1.0896,  0.8537]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0437, 1.8346]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 - working\n",
    "\n",
    "inverse_output = torch.empty(2,2)\n",
    "\n",
    "input_matrix = torch.randn(2,2)\n",
    "indices = torch.tensor([0])\n",
    "print (input_matrix)\n",
    "torch.index_select(input_matrix, 0, indices)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we randomly create the input matrices which is from a normal distribution. The input size is a (2,2) tensor from which we are extracting the first row elements using indexing operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0545, -0.5610, -0.9187, -0.6235],\n",
      "         [-0.5039, -0.8087,  0.4762,  1.1496],\n",
      "         [-0.4608, -0.5587, -0.8092,  0.0364]],\n",
      "\n",
      "        [[-0.8244, -0.3337,  0.1976, -0.1491],\n",
      "         [ 0.3991,  0.9282,  0.2247,  0.4697],\n",
      "         [-1.3364,  0.2710,  2.1608, -0.3268]]])\n",
      "out\n",
      "tensor([[[-0.0545, -0.5610],\n",
      "         [-0.5039, -0.8087],\n",
      "         [-0.4608, -0.5587]],\n",
      "\n",
      "        [[-0.8244, -0.3337],\n",
      "         [ 0.3991,  0.9282],\n",
      "         [-1.3364,  0.2710]]])\n"
     ]
    }
   ],
   "source": [
    "# Example 2 - working\n",
    "\n",
    "input_matrix = torch.randn(2,3,4)\n",
    "indices = torch.tensor([0,1])\n",
    "print (input_matrix)\n",
    "print (\"out\")\n",
    "print (torch.index_select(input_matrix, 2 , indices))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we randomly create the input matrices from a normal distribution. The input is a 3 dimensional tensor of size (2,3,4) from which we are extracting the indices 0 and 1. 0 using index select function. The  `dim` parameter refers to the dimension in which we are interested to select the data with those corresponding indices. In the current example, the outermost dimension the dim value is 0, represents how many matrices are stacked vertically one over the other which is 2 in number. The `dim` value of 1 refers to the rows in those matrices. The `dim` value of 2 refers to the columns in the matrices.\n",
    "From this example, we can see that passing 2 as the `dim` parameter and selecting indices as 0 and 1 we can generate the output of the resulting tensor with the first 2 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-79a87c96faa4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0minput_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking (to illustrate when it breaks)\n",
    "input_matrix = torch.randn(3,3,3)\n",
    "indices = torch.tensor([0,4])\n",
    "print (torch.index_select(input_matrix, 2 , indices))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we randomly create the input matrices which is from a normal distribution. The input size is a 3 dimensional tensor of size (2,3,3) for which we are extracting the first two column elements. But we get an index out of bounds exception as we are trying to select the 4 index which is not present as the dimension of the tensor is (3,3,3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applications of index select functions: \n",
    "Index select functions are possibly used for selecting a particular range of data to understand and get more insights about the data. This function can be used to generate required batch sizes while training the data in machine learning and deep learning applications.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 5 - Cosine similarity\n",
    "\n",
    "This function is not currently present in torch.tensor and is developed by using torch.norm and torch.dot product functions.\n",
    "\n",
    "\n",
    "Cosine similarity measures the similarity between two vectors. It is measured by the cosine of the angle between two vectors and determines whether two vectors are pointing in roughly the same direction. In finding out the similarity at first we calculate the norm corresponding to the two inputs provided and then further on calculating the dot product. \n",
    "\n",
    "if a and b are two vectors then cosine similarity is calculated as:\n",
    "\n",
    "$ angle = inverse(cos(dotproduct(a,b)/(norm(a)).(norm(b)))) $\n",
    "\n",
    "Finally\n",
    "\n",
    "cosine(angle) gives the similarity score between the two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2361)\n",
      "tensor(3.1623)\n",
      "tensor(7., dtype=torch.float64)\n",
      "The score of the cosine similarity is:\n",
      "tensor(0.9899, dtype=torch.float64)\n",
      "The angle between two vectors is:\n",
      "tensor(8.1293, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\70725454\\Anaconda3\\envs\\01-pytorch-basics\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\70725454\\Anaconda3\\envs\\01-pytorch-basics\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Example 1 - working\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def dot_product_calculator(input_numpy_array11, input_numpy_array22):\n",
    "    input_tensor_vector1 = np.array(input_numpy_array11,dtype=np.float64)\n",
    "    input_tensor_vector2 = np.array(input_numpy_array22,dtype=np.float64)\n",
    "    torch_tesnor_vector1 = torch.from_numpy(input_tensor_vector1)\n",
    "    torch_tesnor_vector2 = torch.from_numpy(input_tensor_vector2)\n",
    "    torch_dot_output = torch.dot(torch.tensor(torch_tesnor_vector1),torch.tensor(torch_tesnor_vector2))\n",
    "    return torch_dot_output\n",
    "\n",
    "\n",
    "\n",
    "def vector_norm_caluclator(input_numpy_array):\n",
    "    input_tensor_vector = np.array(input_numpy_array,dtype=np.float64)\n",
    "    torch_tesnor_vector = torch.from_numpy(input_tensor_vector)\n",
    "    torch_norm_output = torch.norm(torch.tensor(torch_tesnor_vector,dtype=torch.float))\n",
    "    return torch_norm_output\n",
    "\n",
    "\n",
    "def main():\n",
    "    input_numpy_array1 = [1.,2.]\n",
    "    input_numpy_array2 = [1.,3.]\n",
    "\n",
    "    vectnorm_1 = vector_norm_caluclator(input_numpy_array1)\n",
    "    vectnorm_2 = vector_norm_caluclator(input_numpy_array2)\n",
    "\n",
    "    print (vectnorm_1)\n",
    "    print (vectnorm_2)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    dot_product_out = dot_product_calculator(input_numpy_array1, input_numpy_array2)\n",
    "    print (dot_product_out)\n",
    "    dot_product_norm = torch.mul(vectnorm_1,vectnorm_2)\n",
    "    \n",
    "    \"\"\"\n",
    "    cosine similarity value and angle\n",
    "\n",
    "    0 value  means two vectors are 90 degrees apart \n",
    "    1 value means two vectors are very close by difference is 0 degrees\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print (\"The score of the cosine similarity is:\")\n",
    "    print ((torch.div(dot_product_out,dot_product_norm)))\n",
    "    print ((\"The angle between two vectors is:\"))\n",
    "    print ((torch.acos(torch.div(dot_product_out,dot_product_norm)))*57.29)\n",
    "\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We give two 1 dimensional vector with two elements as input for which we generate their respective norms and following the dot product. This is performed using torch.norm and torch.dot functions, following we calculate the cosine similarity, and finally, we use the torch.div and torch.acos function. In the above example, we use inputs as [1,2] and [1,3]. The similarity score is found to be 0.9899 and these vectors are found to be 8.1 degrees apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7417)\n",
      "tensor(3.7417)\n",
      "tensor(1., dtype=torch.float64)\n",
      "The score of the cosine similarity is:\n",
      "tensor(0.0714, dtype=torch.float64)\n",
      "The angle between two vectors is:\n",
      "tensor(85.8953, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\70725454\\Anaconda3\\envs\\01-pytorch-basics\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\70725454\\Anaconda3\\envs\\01-pytorch-basics\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Example 2 - working\n",
    "# Example 1 - working\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def dot_product_calculator(input_numpy_array11, input_numpy_array22):\n",
    "    input_tensor_vector1 = np.array(input_numpy_array11,dtype=np.float64)\n",
    "    input_tensor_vector2 = np.array(input_numpy_array22,dtype=np.float64)\n",
    "    torch_tesnor_vector1 = torch.from_numpy(input_tensor_vector1)\n",
    "    torch_tesnor_vector2 = torch.from_numpy(input_tensor_vector2)\n",
    "    torch_dot_output = torch.dot(torch.tensor(torch_tesnor_vector1),torch.tensor(torch_tesnor_vector2))\n",
    "    return torch_dot_output\n",
    "\n",
    "\n",
    "\n",
    "def vector_norm_caluclator(input_numpy_array):\n",
    "    input_tensor_vector = np.array(input_numpy_array,dtype=np.float64)\n",
    "    torch_tesnor_vector = torch.from_numpy(input_tensor_vector)\n",
    "    torch_norm_output = torch.norm(torch.tensor(torch_tesnor_vector,dtype=torch.float))\n",
    "    return torch_norm_output\n",
    "\n",
    "\n",
    "def main():\n",
    "    input_numpy_array1 = [1.,2.,3.]\n",
    "    input_numpy_array2 = [1.,-3.,2.]\n",
    "\n",
    "    vectnorm_1 = vector_norm_caluclator(input_numpy_array1)\n",
    "    vectnorm_2 = vector_norm_caluclator(input_numpy_array2)\n",
    "\n",
    "    print (vectnorm_1)\n",
    "    print (vectnorm_2)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    dot_product_out = dot_product_calculator(input_numpy_array1, input_numpy_array2)\n",
    "    \n",
    "    print (dot_product_out)\n",
    "    \n",
    "    dot_product_norm = torch.mul(vectnorm_1,vectnorm_2)\n",
    "    \n",
    "    \"\"\"\n",
    "    cosine similarity value and angle\n",
    "\n",
    "    0 value  means two vectors are 90 degrees apart \n",
    "    1 value means two vectors are very close by difference is 0 degrees\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    print (\"The score of the cosine similarity is:\")\n",
    "    print ((torch.div(dot_product_out,dot_product_norm)))\n",
    "    print ((\"The angle between two vectors is:\"))\n",
    "    print ((torch.acos(torch.div(dot_product_out,dot_product_norm)))*57.29)\n",
    "\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We give two 1 dimensional vector with three elements as input for which we generate their respective norms and following the dot product. This is performed using torch.norm and torch.dot functions, following we calculate the cosine similarity, and finally, we use the torch.div and torch.acos function. In the above example, we use inputs as [1,2,3] and [1,-3,2]. The similarity score is found to be 0.0714 and these vectors are found to be 85.8953 degrees apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7417)\n",
      "tensor(3.1623)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\70725454\\Anaconda3\\envs\\01-pytorch-basics\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\70725454\\Anaconda3\\envs\\01-pytorch-basics\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "inconsistent tensor size, expected tensor [3] and src [2] to have the same number of elements, but got 3 and 2 elements respectively",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-184-e26564edfb68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-184-e26564edfb68>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mdot_product_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdot_product_calculator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_numpy_array1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_numpy_array2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdot_product_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-184-e26564edfb68>\u001b[0m in \u001b[0;36mdot_product_calculator\u001b[1;34m(input_numpy_array11, input_numpy_array22)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtorch_tesnor_vector1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor_vector1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtorch_tesnor_vector2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor_vector2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mtorch_dot_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch_tesnor_vector1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch_tesnor_vector2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch_dot_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: inconsistent tensor size, expected tensor [3] and src [2] to have the same number of elements, but got 3 and 2 elements respectively"
     ]
    }
   ],
   "source": [
    "# Example 2 - working\n",
    "# Example 1 - working\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def dot_product_calculator(input_numpy_array11, input_numpy_array22):\n",
    "    input_tensor_vector1 = np.array(input_numpy_array11,dtype=np.float64)\n",
    "    input_tensor_vector2 = np.array(input_numpy_array22,dtype=np.float64)\n",
    "    torch_tesnor_vector1 = torch.from_numpy(input_tensor_vector1)\n",
    "    torch_tesnor_vector2 = torch.from_numpy(input_tensor_vector2)\n",
    "    torch_dot_output = torch.dot(torch.tensor(torch_tesnor_vector1),torch.tensor(torch_tesnor_vector2))\n",
    "    return torch_dot_output\n",
    "\n",
    "\n",
    "\n",
    "def vector_norm_caluclator(input_numpy_array):\n",
    "    input_tensor_vector = np.array(input_numpy_array,dtype=np.float64)\n",
    "    torch_tesnor_vector = torch.from_numpy(input_tensor_vector)\n",
    "    torch_norm_output = torch.norm(torch.tensor(torch_tesnor_vector,dtype=torch.float))\n",
    "    return torch_norm_output\n",
    "\n",
    "\n",
    "def main():\n",
    "    input_numpy_array1 = [1.,2.,3.]\n",
    "    input_numpy_array2 = [1.,-3.]\n",
    "\n",
    "    vectnorm_1 = vector_norm_caluclator(input_numpy_array1)\n",
    "    vectnorm_2 = vector_norm_caluclator(input_numpy_array2)\n",
    "\n",
    "    print (vectnorm_1)\n",
    "    print (vectnorm_2)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    dot_product_out = dot_product_calculator(input_numpy_array1, input_numpy_array2)\n",
    "    \n",
    "    print (dot_product_out)\n",
    "    \n",
    "    dot_product_norm = torch.mul(vectnorm_1,vectnorm_2)\n",
    "    \n",
    "    \"\"\"\n",
    "    cosine similarity value and angle\n",
    "\n",
    "    0 value  means two vectors are 90 degrees apart \n",
    "    1 value means two vectors are very close by difference is 0 degrees\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    print ((torch.div(dot_product_out,dot_product_norm)))\n",
    "\n",
    "    print ((torch.acos(torch.div(dot_product_out,dot_product_norm)))*57.29)\n",
    "\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One vector with three elements as input and another input vector with two elements are provided as inputs, we generate their respective norms and following the dot product. In the dot product, we observe that since the vector dimensions are inconsistent we will not able to calculate the cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applications of cosine similarity functions :\n",
    "\n",
    "In natural language processing cosine similarity can be used to find the similarity between the two documents utilizing the word document vector. \n",
    "\n",
    "For the feature vector in machine learning and deep learning problems if we find that two feature vectors are very similar, then we can use it to reduce the dimensionality of the feature space as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we learned about the 5 basic functions of PyTorch tensor which is useful for us in different machine learning models we build in one or the other way. We understood the application and the usage of the mathematical norms which form a fundamental part of the machine learning problem. Another similar function we learned is the dot products which are directly related to the euclidean norm if all the elements are the same in the vector. Using both of these two functions norms and dot products we can find out the cosine similarity between the matrices. Finally, we tested out the inverse functions which are used for identifying the inverse of the square matrices and also we experimented with the index_select function of the torch library which would help to understand how to access the data in different dimensions of the tensor.\n",
    "\n",
    "In the next session, I will be looking forward to building a machine learning or a deep learning model with these fundamental units of Tensors that have been learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Links\n",
    "Provide links to your references and other interesting articles about tensors\n",
    "* Official documentation for `torch.Tensor`: https://pytorch.org/docs/stable/tensors.html\n",
    "* https://en.wikipedia.org/wiki/Cosine_similarity\n",
    "* https://en.wikipedia.org/wiki/Matrix_norm\n",
    "* https://en.wikipedia.org/wiki/Norm_(mathematics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
